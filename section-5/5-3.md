# How Hive Works

This is just a short overview

## Schema on Read

This is what separates it from a normal database.

With real RDB you use a schema on write, and it's enforced.

Hive flips this.

It takes non-schema data and applies one.

Everything might just be tab delimitered text files.

* Hive maintains a "metastore" that imparts a structure you define on the unstructured data that is stored on HDFS etc.

If we wanted to add something via command, we can do this:

```
CREATE TABLE ratings(
    userID INT,
    movieID INT, 
    rating INT,
    time INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH `${env:HOME}/ml-100k/u.data`
OVERWRITE INTO TABLE ratings;
```

This is what happens under the hood. We define a schema on read for something that is already there. And it keeps it on that format.

HIVE doesn't create a relationasl structure, but it takes the existing data, and  imparts a schema when read.


## Where is the data?

* LOAD DATA
    - MOVES data from a distributed filesystem into Hive
    - HIVE manages data, and moves it into HIVE
    - if you have a massive dataset, Hive won't move it, but it would take ownershiop
    - It won't reformat it, but it keeps the schema on its datastore
* LOAD DATA LOCAL
    - This will COPY data from your local file system into Hive
    - Only if not HDFS - but it assumes we're not dealing with big data
* Managed vs External tables
    - Previously it was managed tables where hive manages the data, and owned by hive
    - In the previous ones if you do DROP  TABLE, then it's gone from HIVE
    - but here.....

```
CREATE EXTERNAL TABLE IF NOT EXISTS ratings (
    userID INT, 
    movieID INT,
    rating INT,
    time INT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
LOCATION '/data/ml-100k/u.data';
```

This means that hive will use data here, but it will not own it - so if hive drops the table, the data is not lost. The data is still retained, and it's not moved around.

If  you want to share data, then this is the best way to do it.

## Partitioning

If you have a massive dataset, and its partitioned, hive can do a lot of optimizations. Example

```
CREATE TABLE customers (
    name STRING,
    address STRUCT<street:STRING>, city:STRING, state:STRING, zip:INT>
)
PARTITIONED BY (country STRING);
```

If you take a partition, then you would actually be storing the partitions in a sub-directory, so it woudl have a partition-based structure.

It would save a lot of time, as you would only scan to the files of the countries you'd be interested in.

You can do more structured things than just ints, etc. You can create STRUCTUCTS. You can also store MAPS as well.

## Ways to use Hive

* Interactive via hive> prompt / Command line interface
* Saved query files
    - hive -f / somepath/queries.hql
* Through Ambari/Hue
* Through JDBC/ODBC server (like any other db)
* Through Thrift service
    - But remember, hive is not suitable for OLTP (online transaction processing - you'd use HBase instead)
* Via Oozie




