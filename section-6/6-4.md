
# HBase / Pig Integration - Populating HBase at Scale

Integrating HBase with PIG

How to populate HBase table with big data.

# Integrating Pig with HBase

* Must create HBase table ahead of time
* Your relation must have a unique key s its first column followed by subsequent columns as you want them saved in HBase
* Using clause allows you to store into an HBase table 
* Can work at scale - HBase is transactional on rows

# Let's do this!

Import the users table from the movielens dataset...

Next thing we need to do is to import it via PIg and then to the HBase.

We first create the relevant table in HBASE

```
hbase shell
```

Opens the interactive terminal, so we can run the following commands:

```
list
create 'users','userinfo'
list
exit
```

Now let's download the script:

```
wget http://media.sundog-soft.com/hadoop/hbase.pig
```

Let's see what's inside the file:

```
USING PigStorage('|')
AS (userID:int, age:int, gender:chararray, occupation:chararray, zip:int);

STORE users INTO 'hbase://users'
USING org.apache.pig.backend.hadoop.hbase.HBaseStorage (
'userinfo:age,userinfo:gender,userinfo:occupation,userinfo:zip');
```

Now let's run it!

```
pig hbase.pig
```

Pig is kicking off a map reduce job to process this. 

Now let's check in hbase through the shell

```
hbase shell
list
scan 'users'
```

Now we can see some data. We can see that we can see the column names, including our userinfo, but also the automatically added timestamp and value.

Now to drop a table:

```
disable 'users'
drop 'users'
list
```

Now let's just stop the HBase service.

There are other noSql or non relational technologies that we might interate to 


