# MongoDB

Managing HuMONGOus data

Popular choice for corporates

But what's good about mongo is its document model

# Where are we in the CAP theorem?

Mongo sits closer to partition tolerance and also consistency, but not availability.

# Document-based data model

You can put anything you want into MongoDB - it doesn't have to be structured, you don't have to have the same schema, etc

The structure is typeical JSON.

``` json
{
    "_id": ObjectID("13je09j3"),
    "title": "post",
    ...
}
```

# No real schema is enforced

* You can have different fields in every document if you want to 
* No single "key" as in other databases
    - But you can create indices on any fields you want, or even combinations of fields
    - If you want to "shard", then you must do so on some index
* Results in a lot of flexibility
    - But with great power comes great responsibility

# MongoDB terminology

* Databases
    - Contains collections (instead of tables)
* Collections
    - Contains documents (instead of rows)
    - Can't move collections across databases
* Documents

## It's kinda Corporate-y

The description in the website is messaged towards sales people in corporates

# Replication sets

* Single master architecture - consistency over availability
* Maintains backup copies of your databse instance
    - Secondaries can elect a new primary within seconds if your primary goes down
    - But make sure your operation log is long enough to give you time to recover the primary when it comes back

This is not about big data - we're talking about a monolithic primary server with backup copies in multiple otherss

# Replica set quirks

* A majority of servers in your set must agree on the primary
    - Even numbers of servers (like 2) don't work well
* Don't want to spend money on 3 servers? you can setu pan 'arbiter' node (but only one)
* Apps must know about enough servers in the replica set to be able to reach one to learn who's primary
* Replicas only address durability, not your ability to scale
    - Well unless you can take advantage of reading from secondaries - which isn't recommended
    - And your DB will still go into read-only mode for a bit while a new primary is being elected
* Delayed secondaries can be set up as insurance against people during dumb things

# Sharding

* Finally big data
* Ranges of some indexed value  you specify are assigned to different replica sets

The way sharding works is we have multiple replica sets! Where each replica set is responsible on a specific set of IDs. 
It requires a unique value, and the index is used to balance the info across multiple replica sets!
Then it talks to Application Servers that runs MongoS that talks to config servers that know how is partitioned and who to talk to to query stuff.

Mongos is running a balancer in the background, and finds if there is not an even distribution in the shards, it can rebalance the sharding on the index.

# Sharding Quirks

* Auto-sharding sometimes doesn't work
    - Split storm - mongos processes restarded too often things will never rebalance
        + If you restart too often you end up with this...
* You must have 3 config servers
    - And if any 1 goes down, your db goes down 
        + This is similar to HBase
        + Tradeoff of consistency for availability
* MongoDB's loose doc model cna be at odds with effective sharding

# Neat thigns about MongoDB

* It's not just a NoSQL db - very flexible document model
* Shell is a full javascript interpreter
    - You can run javascript code across the db
* Supports many indices
    - But only one can be used for sharding
    - More than 2-3 are still discouraged
    - Full-text indices for text searches
    - Spatial indices
* Built-in aggregation capabilities, MapReduce, GridFS
    - For some applications you might not need hadoop at all
    - But MongoDB still integrates with Hadoop, Spark and most langauges
* A SQL connector is available 
    - But MongoDB isn't designed for joins and normalized data really
