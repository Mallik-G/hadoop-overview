# Choosing your database

There are so many choices - you might not even need an external database!

People that make these decisions make the big bucks!

## Integration considerations

What systems do you need to integrate together?

If you have an analytics job with apache spark, you might want to limit to databases that integrate easily to Apache spark.

Mayeb you have a frontend system that requires a SQL interface, and you want to move to NoSQL, so you might need to have a database that has a SQL-like interface!

ALso make sure that the components are maintained.

# Scaling requirements

Is data going to grow unbounded over time?

If so you don't want to be stuck with 1 PC. You might have to get Cassandra, HBase, etc

How many requests per second will you be getting? 1000p/s? THen you need a NoSQL sort of stuff.

You have a website with a lot of web servers serving it - big website, then you 'll ned a Nosql more than monolithic SQl

# Support considerations

How much support will you need? Do you have personally indentifyable information?  SECURITY!!

NoSQL databases need to have security in mind

If you are in big organisation with these experts in house, then its good

BUt in smaller orgnisations you need to think how you're gonna get administration for security over time.

In these cases something like MongoDB it might make sense.

But also for apache stuff there are paid professionals that offer support.

# Budget considerations

You probably won't be thinking about money as much as it's all open source, right now the cost is the cost of the servers themselves.

It can't be significant - you can rent the servers tbh...

Budget often isn't a concern... If you're working at a company budget won't be biggest concern

# CAP consideration

We need to make sure we consider Consistency, Availability or Partition Tolerance?

* Partition Tolerance 
    - Sufficient scale where you're going to need more than 1 server to handle the data
    - TO handle the requests
    - Then this is non-negotiable
* Availability
    - Is it ok if your system goes down for a few seconds/minutes
* Consistency
    - Is it ok where you have eventual consistency, where people might get the same read a few times until
    - If doing transactions, it's improtant to have consistency

It's worth pointing out that the CAP theorem isn't a dogma... the tradeoffs have become more loose.

ie CASSANDRA - is it really that they are trading off consistency? Well now you can tweak it! If you're running it in the mode with less node acknowledgements you can get closer to the consistency angle!

Any of these technologies can be made work if pushed hard enough

but it's about choosing the best technology that is relevant

Even MySQL can be sharded, but screw that...

# Simplicity

Keep it simple!!

Above all!

If you don't need to setup a highly complex nosql cluster that needs so much consistency, and configuration management, then don't do it!

Think about the minimum requirements and keep it like that!

If you don't need massive scale, don't deploy for massive scale!

You don't want to be randomly woken out at 2am...

Keeeep it simple...

# An Example!!

* You are building an internal phone directory app
    - Scale: Limited
    - Consistency: Eventual is fine
    - Availability requirements: Not mission critical
    - MySQL is probably already installed on your server...

# Another example

* You want to mine web server logs for interesting patterns
* What are the most popular times of dat? What's the average session length?

This is like google analytics for my website. 

How to approach it?

Step back and ask - do I have enough scale to warrant a NoSQL...

If I just want analytics, that's why Hadoop is for.

We can just analyse it by extracting it to our HDFS, etc.

If you don't have something about high transations, getting a query 1000s times per second. 

If you don't have that problem - don't do it.

Because we don't we can just import that data into HDFS, but doesn't involve external databases at all.

We can write spark job that mines that data, assigns structure to it, and use stuff like Spark, Hive, PIG, or even connect Tableu 

If we were building google analytics for real and you have millions of people hitting the db, then you might need a NoSQL, but because you don't just don't use all that stuff.

JUst use the hadoop ecosystem.

# Another example

* You have a big spark job that produces movie recommendations for end users nightly
* Something needs to vend this data to your web applications
* You work for some huge company with massive scale
* Downtime is not tolerated
* Must be fast
* Eventual consistency OK - it's just reads

Because it seems that we care about availability and partition tolerance, it seems that cassandra is the best choice! 








