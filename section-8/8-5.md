# Zookeeper Overview

## What is Zookeeper 

* It basically keeps track of information that must be synchronised across your cluster
    - Which node is the master?
    - What tasks are assigned to which workers?
    - Which workers are currently available?
* It's a tool that applications can use to recover from partial failures in your cluster
    - There are a lot of failures - nodes go down, storms in netowrk, weird partitions, clocks drift, systems think they are in different timezone, etc
* An integral part of HBase, High Availability (HA) MapReduce, Drill, Storm, Solr and much more

## Failure Modes

* Master crashes (yarn, etc), needs to fail over to a backup
    - Other msters run as backup
    - Clients agree who to talk to 
    - Let other masters to choose 1 master
* Worker crashes
    - Its work needs to be distributed
    - Will notify application hthat it happene
* Network trouble
    - Different datacenters, and for some reason cannot talk
    - Zookeeper will be able to identify - whether worker can be reached or not

# Primitive operations in a distributed system

* Master election
    - One node reigsters itself and holds a lock on that data
    - Other nodes cannot become master until that lock is released
    - Only one node allowed to hold the lock at a time
* Crash detection
    - "Ephimeral" data on a node's availability automatically goes away if the node disconnects, or fails to refresh itself after some time-out period
* Group management
    - What workers are available in the pool
* Metadata 
    - List of outstanding tasks, task assignments

# Zookeeper API 

* Really a little DFS
    - With strong consistency guarantees
    - Replace the concepts of "file" with "znode" and you've pretty much got it
* Here's the zookeeper API
    - Create, delete, exists, setData, getData, getChildren
        + EXAMPLE
        + /
            * /master - "master1.foobar.com:2223"
            * /workers
                - worker-1 "worker-2.foobar.com:2225"
                - worker-2 "worker-5.foobar.com:2225"

# Notifications

* A client can register for notifications on a znode
    - Avoids continuous polling
    - Example: register for notification on / master - if it goes away, try to take over as the new master

# Persistent and ephemeral znodes

* Persistent znodes remain stored until explicitly deleted
    - ie assignemnt of tasks to workers must persist even if master crashes
* Ephemeral znodes go away if the client that created it crashes or loses its connection to zookeeper
    - ie if the master crashes it should release its lock on the znode that indicates which node is the master 

# Zokeeper architecture

Every client in applciation will talk to Zookeeper master / worker
There will be a zookeeper ensemble, which is more than 1 server, and that's called an ensemble
Zookeeeper clients need to keep track of all of the clients.
Ensemble should replicate data amongst themselves.
You can select consistency level of X number of servers before stuff happens

# Zookeeper Quorums

Similar to MongoDB

You can specify the number of servers agreeing in order to do stuff. You normally want 3 zookeeper servers to agree. You often would want more than 5 zokeeper servers.

If you have 5 servers, 3 in one, 2 in other, then you might have part of zookeeper providing an answer to clients, and other part providing other answer.

Zookeeper is required to be careful how to set up.

AS long as a quorum of 3 decides, then it's ok. You need at least 5 servers iwth an answer of minimum 3

Sounds a lot like how Mongo works! Zookeeper has the same problems than mongodb when it comes to availability and consistency.

Since the tradeoff is in availability, we have consistency and partition stuff.



 


