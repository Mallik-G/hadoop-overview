# Setting up drill

We're gonan:
* Get our mongodb up and running
* Re-import movielens data
* Setup hive db with movie ratings
* Search everything

# Ambari dashboard

We're first gonna log in as admin and spin back up the databases:

* Start mongodb
* Go to hive
    - Import ratings data into hive

Start creating a database for it to live in:

```
CREATE DATABASE movielens
```

We can now see database, let's upload data in Upload data, and import u.data.

Name table ratings with same columns as before user_id, movie_id, rating, epoch_seconds.

Let's run ```SELECT * FROM ratings LIMIT 100;```

# Adding to mongo

Let's ssh to our computer.

We should still have the MongoSpark.py file that we can run to export the data from spark to mongodb.

We'll be using Spark 2 to import the data from HDFS into mongo.

Let's run:

```
SPARK_MAJOR_VERSION=2
spark-submit --packages org.mongodb.spark:mongo-spark-connector_2.11:2.0.0 MongoSpark.py
```

When we kick that off, we should see the 20 rows successfully.

Now that we have the data in place we shoulds just install drill.

Let's run the following command:

```
wget http://mirrors.supportex.net/apache/drill/drill-1.10.0/apache-drill-1.10.0.tar.gz
```

We would normally want to install it in a more permanent directory, but for now it should be fine...

Let's start by untaring it...

```
tar -xvf apache-drill-*
```

Now we have the directory we cd to, we can see the bin directory, and that's all we need.

When running drill we need to give it a diffeernt port. But we need to give it a port that is accessible. It's not as simple as opening the port in the virtualbox environment.

The reason why, is because the HDP image is running inside a docker container within virtual box... We will configure DRILL to run on a port that is open but unused 

let's run it by doing:

```
bin/drillbit.sh start -Ddrill.exec.http.port=8765
```

And drill is running - now we can go to 127.0.0.1:8765 and it works!

We now need to conenct drill to our instances!

To do that we can hit the storage tab...

We can ssee that hive and mongo are disabled - let's hit enable in both.

Now let's hit update in Hive, and we can see a "hive.metastore.uris"... **we need to change the value to thrift://localhost:9083**, which should look like this:

``` json
{
  "type": "hive",
  "enabled": true,
  "configProps": {
    "hive.metastore.uris": "thrift://localhost:9083",
    "javax.jdo.option.ConnectionURL": "jdbc:derby:;databaseName=../sample-data/drill_hive_db;create=true",
    "hive.metastore.warehouse.dir": "/tmp/drill_hive_wh",
    "fs.default.name": "file:///",
    "hive.metastore.sasl.enabled": "false"
  }
}
```

Mongo would work out of the box... if there is a different connection string you can change it there...

Now we're ready to drill!




