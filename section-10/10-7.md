# Counting words with Flink

Kick of VM, ssh.

Flink doesn't come pre-installed! So we need to get it and install it

Let's go to flink.apache.org -> Download. 

```
wget http://apache.hippo.nl/flink/flink-1.3.0/flink-1.3.0-bin-hadoop27-scala_2.10.tgz

tar -xvf flink-1.3.0-bin-hadoop27-scala_2.10.tgz
cd flink flink-1.3.0-bin-hadoop27-scala_2.10.tgz

ls
```

We're just gonna run a local Flink file, and one of the examples

Change configuration!

```
cd conf

# flink-conf.yaml
# change jobmanager.web.port to 882
vim flink-conf.yaml

cd ..
./bin/start-local.sh
```

We can pull the web ui and open 127.0.0.1:8082 for the flink dashboard

# run example

We're gonna run another wordcount example.

Looks similar to the Spark Streaming - not just because it's scala but how it's structured.

* We create a SocketWindowWordCount
    - Count the number of times words appear
    - We have a main function
        + Basic initialisation
        + Get streamexecution env
        + get a sockettextstream from a tcp port
        + Then we do the text stream, 
            * call flatMap (to split words)
            * Do the map (x,1) tuple
            * KeyBy
            * timeWindow of 5 seconds (tumbling windwos)
            * And then the sum(count)
    - We make it run in one thread
    - AND WE RUN IT!

Let's run it!

```
nc -l 9000
```

Now let's  open another window to kcik off a streaming job

```
cd flink-1.3.0

./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000
```

On the input terminal, let's type

```
i am a rock i am an insland
rock
rock
```

Now let's see the results, but we ened to see the logs, so we need another window...

```
cd flink-1.3.0

cd log

ls

cat flink-maria_dev-jobmanager-0-sandbox.hortonworks.com.out
```

And we can see the count

```
i : 2
insland : 1
an : 1
rock : 3
a : 1
am : 2
```

It works!

Let's finally shut down the service with ```./bin/stop-local.sh```







