
# Running with MRJob

We can run it in multiple ways:

* Run locally 
    - python FILENAME.py DATA.data
* Run with Hadoop
    - python FILENAME.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar DATAFILE.data

For hadoop sandbox we have to specify where exactly the streamer is, however for other services like AWS MR, it would find it.

## Running our data

``` bash
    python RatingBreakdown.py u.data
```
The output is 

```
Creating temp directory /tmp/RatingsBreakdown.maria_dev.20170529.113431.599566
Running step 1 of 1...
Streaming final output from /tmp/RatingsBreakdown.maria_dev.20170529.113431.599566/output...
"5" 21203
"1" 6111
"2" 11370
"3" 27145
"4" 34174
Removing temp directory /tmp/RatingsBreakdown.maria_dev.20170529.113431.599566...
```

## Running in hadoop cluster

Now we can run it in the hadoop cluster

``` bash
python RatingsBreakdown.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar u.data
```

And it worked!