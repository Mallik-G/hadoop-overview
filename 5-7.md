
# Using Sqoop to extract data from MySQL

We imported the movielens dataset to SQL, so we'll use Sqoop to import the data from MySQL to HDFS

First we need to access the right permissions.

Let's log in on MySQL, and execute the following
```
GRANT ALL PRIVILEGES ON movielens.* to ''@'localhost';
exit
```

Now let's run sqoop.

```
sqoop import --connect jdbc:mysql://localhost/movielens --driver com.mysql.jdbc.Driver --table movies -m 1
```

Remember that These tools are intended for Big Data. It doesn't make sense to use small datasets with this.

There is loads of things to be done, it's launching MR to transfer everything... AND.... it's done!

Let's check the Ambari dashboard in Files View!

It's there. Because we specified 1 mapper, we only have 1 file. If we had more mappers we've had more.

If we open it, we can see CSV data.

```
1,Toy Story (1995),1995-01-01
2,GoldenEye (1995),1995-01-01
3,Four Rooms (1995),1995-01-01
4,Get Shorty (1995),1995-01-01
5,Copycat (1995),1995-01-01
6,Shanghai Triad (Yao a yao yao dao waipo qiao) (1995),1995-01-01
7,Twelve Monkeys (1995),1995-01-01
8,Babe (1995),1995-01-01
9,Dead Man Walking (1995),1995-01-01
10,Richard III (1995),1996-01-22
11,Seven (Se7en) (1995),1995-01-01
12,Usual Suspects, The (1995),1995-08-14
```

The good thing is that the file might be distributed across the cluster in multiple parts. Making it also resilient to failure.

Let's delete that directory.

# Importing straight to HDFS

If we don't care about our files and we just want to import it to hive...

Back to our CMD - We can run it with the --hive-import flag:

```
sqoop import --connect jdbc:mysql://localhost/movielens --driver com.mysql.jdbc.Driver --table movies -m 1 --hive-import
```

Again we can see it's kicking off. We can also see kafka is mentioned - we haven't mentioned it, but it's another Highly distributed tool to broadcast data to a cluster. 

When it's done we can go to the Hive dashboard view, and under the tables, we can try to check it.

When we run the SELECT query, we can see all our data is there!





