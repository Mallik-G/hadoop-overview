# How pieces fit together

And how to use them in real life problems.

# Reviewing different technologies

Let's remind ourselves how each technology reflects to each other

* If we're just talking about hadoop, we have
    - HDFS, breaks files across the cluster
    - YARN, manages the computation and processing of data (which processes, etc)
    - MapReduce, Transform and aggregate data across your cluster
* On top of Hadoop
    - Hive, SQL queries, MR and YARN
    - Pig, sits at same level, scripting interface, pig latin
* TEZ - alternative to Map Reduce, uses a DAG, more efficient
* Spark - Based on DAGs , really fast, not just a middle layer, uses scala/python/java
* HBase - Sits alongside Hadoop Technologies, NoSQL relational DB

## Other external dbs

* MySQL - relational, normally integrate
* MongoDB - Similar to HBase in design, but more general purpose
* Cassandra - NoSQL, architecture is avialability out of everything else

## Data Ingestion

* Sqoop
    - Export/export data from MySQL or relational dbs using MR under the hood

## Job tracking

* Zookeeper
    - Keeps trakc of jobs
* Oozie
    - Allows you to orchestrate workflows of jobs

# Query engines

* Hue - Interface for cloudera (ambiguous to ambari)
* Drill - SQL to query a lot of hadooop stuff except cassandra
* Presto - Facebook's SQL engine for again cassandra + everything except HBase
* Phonix - SQL for HBase
* Zeppelin - Web based notebook for running spark, etc.

# Streaming technologies

* Apache storm
    - Tightly integrated to hadoop 
* Spark Streaming
    - Spark based Streaming
* Flink
    - New up and coming processing simlar to spark streaming
* Kafka 
    - Generic pub-sub streamer
* Flume
    - Hadoop-specific pub-sub streamer

# At the very top

**Ambari!**












